{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmacdonald347/MLforNLP1/blob/main/Copy_of_LAB_9_1_pytorch_tensor_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktTpk9bCr_Lg"
      },
      "source": [
        "# **PyTorch Basics Tutorial**\n",
        "\n",
        "The following tutorial is a slightly modified of the [pytorch basics colab notebook](https://colab.research.google.com/drive/1-L2LJmiV_rgCtzsIJOMfF_9fwJuxsj09), from [Diyi Yang's NLP course](https://www.cc.gatech.edu/classes/AY2020/cs7650_spring/).\n",
        "\n",
        "The notebook is itself adapted from the [DeepLearningForNLPInPytorch tutorial](https://github.com/rguthrie3/DeepLearningForNLPInPytorch/blob/master/Deep%20Learning%20for%20Natural%20Language%20Processing%20with%20Pytorch.ipynb) and the [Official PyTorch tutorials](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#sphx-glr-beginner-blitz-tensor-tutorial-py).\n",
        "\n",
        "PyTorch is a python library for deep learning, mainly developed by FaceBook, in open source. It is a python re-implementation of torch, a package initially developed at IDIAP (Switwerland) by Collobert, Bengio and Mariéthoz.\n",
        " PyTorch uses underlying C libraries, for more speed.\n",
        "\n",
        "A PyTorch characteristic is that the backpropagation algorithm can be applied to a **dynamically defined computation graph**, whereas TensorFlow (Google's library for deep learning) was originally developped using static computation graphs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gT-s9_PdslEW"
      },
      "source": [
        "## if running on your computer : torch installation\n",
        "\n",
        "see precise installation command at https://pytorch.org/get-started/locally/\n",
        "\n",
        " - your computer has CPU only\n",
        " - no need for torchvision nor torchaudio\n",
        "\n",
        "**Via Anaconda/Miniconda:**  \n",
        "`conda install pytorch -c pytorch`\n",
        "\n",
        "**Via pip:**  \n",
        "`pip3 install torch`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlRjjJqDr5bs",
        "outputId": "e28fd4b2-c631-4e36-8120-8b92da579e21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu118\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaso_dtjsExr"
      },
      "source": [
        "## 1 the Tensor type in torch\n",
        "Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
        "\n",
        "### 1.1 Creating Tensors from data\n",
        "Tensors can be created from Python lists with the `torch.Tensor()` function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpQ5Oek2s4ca",
        "outputId": "7b27fc31-79ed-4c58-9c9e-7cfb7350ecc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example with 1-D data\n",
            "tensor([1., 2., 3.])\n",
            "\n",
            "Example with 2-D data\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "\n",
            "Example with 3-D data\n",
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n"
          ]
        }
      ],
      "source": [
        "# Example with 1-D data\n",
        "data = [1.0, 2.0, 3.0]\n",
        "tensor = torch.Tensor(data)\n",
        "print(\"Example with 1-D data\")\n",
        "print(tensor)\n",
        "\n",
        "# Example with 2-D data\n",
        "data = [[1., 2., 3.], [4., 5., 6]]\n",
        "tensor = torch.Tensor(data)\n",
        "print(\"\\nExample with 2-D data\")\n",
        "print(tensor)\n",
        "\n",
        "# Example with 3-D data\n",
        "data = [[[1.,2.], [3.,4.]],\n",
        "        [[5.,6.], [7.,8.]]]\n",
        "tensor = torch.Tensor(data)\n",
        "print(\"\\nExample with 3-D data\")\n",
        "print(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b18oELGNvhNg"
      },
      "source": [
        "### 1.2 Initializing an empty Tensor\n",
        "An uninitialized matrix is declared, but does not contain definite known values before it is used. When an uninitialized matrix is created, whatever values were in the allocated memory at the time will appear as the initial values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kg_gi1AWv_1E",
        "outputId": "80b0a054-d41a-4e09-907a-c948038c2f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.3921e-05,  3.3344e-41, -1.3926e-05],\n",
            "        [ 3.3344e-41,  3.5032e-44,  8.3997e-33]])\n"
          ]
        }
      ],
      "source": [
        "# Construct a 2x3 matrix, uninitialized\n",
        "x = torch.empty(2, 3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDr4ZzQrwOmZ"
      },
      "source": [
        "### 1.3 Randomly initialized Tensor\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0pZQfUywgwL",
        "outputId": "57367dbd-d660-45c4-be50-171b829e7280"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5805, 0.0918, 0.4665],\n",
            "        [0.9227, 0.2297, 0.6936]])\n"
          ]
        }
      ],
      "source": [
        "x = torch.rand(2, 3)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLJOlS32wjFg"
      },
      "source": [
        "### 1.4 Tensor with zeros or ones"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JQ0JM9njwtFr",
        "outputId": "2a3c8f19-76a2-4ea8-c1e2-aaed8c911f2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matrix of zeros\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "\n",
            "Matrix of zeros typecasted to long\n",
            "tensor([[0, 0, 0],\n",
            "        [0, 0, 0]])\n",
            "\n",
            "Matrix of ones typecasted to long\n",
            "tensor([[1, 1, 1],\n",
            "        [1, 1, 1]])\n"
          ]
        }
      ],
      "source": [
        "# Create a matrix of all zeros\n",
        "x = torch.zeros(2, 3)\n",
        "print(\"Matrix of zeros\")\n",
        "print(x)\n",
        "\n",
        "# Create a matrix of all zeros and explicitly set data type to be long int\n",
        "x = torch.zeros(2, 3, dtype=torch.long)\n",
        "print(\"\\nMatrix of zeros typecasted to long\")\n",
        "print(x)\n",
        "\n",
        "x = torch.ones(2, 3, dtype=torch.long)\n",
        "print(\"\\nMatrix of ones typecasted to long\")\n",
        "print(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0HQKRy2wsDd"
      },
      "source": [
        "### 1.5 Create Tensor based on existing Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "visdOehpxqd-",
        "outputId": "def5c166-1e90-4106-e78a-48dc9603ec69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float64)\n",
            "tensor([[ 1.3917, -1.3365, -0.3134],\n",
            "        [ 1.8803, -0.1613, -0.3868]])\n"
          ]
        }
      ],
      "source": [
        "x = x.new_ones(2, 3, dtype=torch.double)      # new_* methods take in sizes\n",
        "print(x)\n",
        "\n",
        "x = torch.randn_like(x, dtype=torch.float)    # override dtype!\n",
        "print(x)                                      # result has the same size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HLZfCcObzBTe"
      },
      "source": [
        "### 1.6 Size of a Tensor\n",
        "`torch.Size` is in fact a tuple, so it supports all tuple operations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YVIu-uZnzEm-",
        "outputId": "106a8327-14fe-4375-e7cb-e9210cf0ee0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example with 1-D data\n",
            "tensor([1., 2., 3.])\n",
            "torch.Size([3])\n",
            "\n",
            "Example with 2-D data\n",
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "torch.Size([2, 3])\n",
            "\n",
            "Example with 3-D data\n",
            "tensor([[[1., 2.],\n",
            "         [3., 4.]],\n",
            "\n",
            "        [[5., 6.],\n",
            "         [7., 8.]]])\n",
            "torch.Size([2, 2, 2])\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# Example with 1-D data\n",
        "data = [1.0, 2.0, 3.0]\n",
        "tensor = torch.Tensor(data)\n",
        "print(\"Example with 1-D data\")\n",
        "print(tensor)\n",
        "print(tensor.size())\n",
        "\n",
        "# Example with 2-D data\n",
        "data = [[1., 2., 3.], [4., 5., 6]]\n",
        "tensor = torch.Tensor(data)\n",
        "print(\"\\nExample with 2-D data\")\n",
        "print(tensor)\n",
        "print(tensor.size())\n",
        "\n",
        "# Example with 3-D data\n",
        "data = [[[1.,2.], [3.,4.]],\n",
        "        [[5.,6.], [7.,8.]]]\n",
        "tensor = torch.Tensor(data)\n",
        "print(\"\\nExample with 3-D data\")\n",
        "print(tensor)\n",
        "print(tensor.size())\n",
        "print(tensor.size()[0]) # taille de la 1ere dim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYai6C6H0kKx"
      },
      "source": [
        "### 1.7 Operations with Tensors\n",
        "Most operations are very similar to NumPy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRj42hPO0prW",
        "outputId": "8e3f2451-a6ba-4581-db86-e73233159e6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n",
            "tensor([5., 7., 9.])\n",
            "tensor([5., 7., 9.])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-38954958df63>:14: UserWarning: An output with one or more elements was resized since it had shape [2, 3], which does not match the required output shape [3]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
            "  torch.add(x, y, out=output)\n"
          ]
        }
      ],
      "source": [
        "# Addition\n",
        "x = torch.Tensor([ 1., 2., 3. ])\n",
        "y = torch.Tensor([ 4., 5., 6. ])\n",
        "\n",
        "# using arithmetic operation\n",
        "z = x + y\n",
        "print(z)\n",
        "\n",
        "# using method\n",
        "print(torch.add(x, y))\n",
        "\n",
        "# using method and providing an output tensor as argument\n",
        "output = torch.empty(2, 3)\n",
        "torch.add(x, y, out=output)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjy0Zqik0-wL",
        "outputId": "d3fe46fc-b3b2-4fd8-ef3e-63612484b315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([5., 7., 9.])\n"
          ]
        }
      ],
      "source": [
        "# In-place addition\n",
        "\n",
        "x = torch.Tensor([ 1., 2., 3. ])\n",
        "y = torch.Tensor([ 4., 5., 6. ])\n",
        "\n",
        "y.add_(x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFetPkbO1750"
      },
      "source": [
        "Any operation that mutates a tensor in-place is post-fixed with an underscore `_`. For example: `x.copy_(y)`, `x.t_()`, will change `x`.\n",
        "\n",
        "See [the PyTorch official documentation](http://pytorch.org/docs/torch.html) for a complete list of the massive number of operations available to you.  They expand beyond just mathematical operations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gedfbDbd06Fn",
        "outputId": "fc57617c-3b08-4b78-f5d7-144043195344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2., 3.],\n",
            "        [4., 5., 6.]])\n",
            "tensor([2., 5.])\n"
          ]
        }
      ],
      "source": [
        "# Indexing\n",
        "\n",
        "x = torch.Tensor([[1., 2., 3.], [4., 5., 6]])\n",
        "print(x)\n",
        "print(x[:, 1]) # Gets column with index 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IqeYxdg3Bvk"
      },
      "source": [
        "### 1.8 Reshaping Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUwsXsfw26g_",
        "outputId": "7f00a7e5-da6d-4dd5-b0e3-f6277e149f99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15]])\n",
            "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
            "        [ 8,  9, 10, 11, 12, 13, 14, 15]])\n",
            "torch.Size([4, 4]) torch.Size([16]) torch.Size([2, 8])\n"
          ]
        }
      ],
      "source": [
        "#@@ view in pytorch is the equivalent of reshape in numpy\n",
        "x = torch.tensor(range(16)).view(4,4)\n",
        "print(x)\n",
        "y = x.view(16)\n",
        "print(y)\n",
        "z = x.view(-1, 8)  # the size -1 is inferred from other dimensions\n",
        "print(z)\n",
        "print(x.size(), y.size(), z.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EfLY9rk7hfI",
        "outputId": "bd474015-8e20-4465-a1a9-2c4d75790376"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  1,  2,  3],\n",
            "        [ 4,  5, 17,  7],\n",
            "        [ 8,  9, 10, 11],\n",
            "        [12, 13, 14, 15]])\n",
            "tensor([[ 0,  1,  2,  3,  4,  5, 17,  7],\n",
            "        [ 8,  9, 10, 11, 12, 13, 14, 15]])\n"
          ]
        }
      ],
      "source": [
        "#@@ underlying data is NOT copied\n",
        "x[1,2] = 17\n",
        "print(x)\n",
        "print(z)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYbIGqaZ7hfK",
        "outputId": "f7432fa7-4866-410e-a012-aeb10c771ad3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 8])\n",
            "torch.Size([4, 4])\n"
          ]
        }
      ],
      "source": [
        "#@@ .shape is equivalent to .size()\n",
        "print(z.shape)\n",
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd2l465j7hfK"
      },
      "source": [
        "### Changing the number of axis of a tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IahJhMUs7hfL",
        "outputId": "2ea606bd-8967-439b-91c0-7b7992df53a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.5573,  0.7979, -1.9616])\n",
            "torch.Size([3])\n",
            "tensor([[-1.5573],\n",
            "        [ 0.7979],\n",
            "        [-1.9616]])\n",
            "torch.Size([3, 1])\n",
            "tensor([[-1.5573,  0.7979, -1.9616]])\n",
            "torch.Size([1, 3])\n",
            "tensor([[[-1.5573],\n",
            "         [ 0.7979],\n",
            "         [-1.9616]]])\n",
            "torch.Size([1, 3, 1])\n"
          ]
        }
      ],
      "source": [
        "#@@ view can hence also be used to add a 1-sized axis\n",
        "x = torch.randn(3)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "\n",
        "print(x.view(3,1))\n",
        "print(x.view(3,1).shape)\n",
        "\n",
        "# if -1 can be used, the size on this axis will be automatically computed\n",
        "print(x.view(-1,3))\n",
        "print(x.view(-1,3).shape)\n",
        "\n",
        "print(x.view(-1,3,1))\n",
        "print(x.view(-1,3,1).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5VX9mZC7hfL",
        "outputId": "ac1ea54b-8934-4c98-ddeb-49c4a4c87d6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-1.1234,  0.3913, -0.6254])\n",
            "torch.Size([3])\n",
            "tensor([[-1.1234,  0.3913, -0.6254]])\n",
            "torch.Size([1, 3])\n",
            "tensor([[-1.1234],\n",
            "        [ 0.3913],\n",
            "        [-0.6254]])\n",
            "torch.Size([3, 1])\n"
          ]
        }
      ],
      "source": [
        "# unsqueeze adds an axis of size 1\n",
        "x = torch.randn(3)\n",
        "print(x)\n",
        "print(x.shape)\n",
        "\n",
        "# add an axis as first axis (cf. dim=0)\n",
        "y= x.unsqueeze(dim=0)\n",
        "print(y)\n",
        "print(y.shape)\n",
        "\n",
        "# add an axis as second axis\n",
        "z= x.unsqueeze(dim=1)\n",
        "print(z)\n",
        "print(z.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egSiriE-7hfM",
        "outputId": "5c017169-a93f-4d2d-b78c-4deb0d4848cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5]\n",
            "z tensor([0, 1, 2, 3, 4, 5])\n",
            "y tensor([[0, 1, 2, 3, 4, 5]])\n",
            "x tensor([[[[0],\n",
            "          [1],\n",
            "          [2]]],\n",
            "\n",
            "\n",
            "        [[[3],\n",
            "          [4],\n",
            "          [5]]]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5]])\n",
            "torch.Size([2, 3, 1])\n",
            "torch.Size([2, 1, 3, 1])\n"
          ]
        }
      ],
      "source": [
        "# squeeze removed all axis having size 1\n",
        "print(list(range(6)))\n",
        "\n",
        "z = torch.tensor(range(6))\n",
        "print(\"z\", z)\n",
        "y = z.view(1, -1)\n",
        "print(\"y\", y)\n",
        "x = torch.tensor(range(6)).view(2,1,3,1)\n",
        "print(\"x\", x)\n",
        "# squeeze will remove any axis of size 1\n",
        "print(x.squeeze())\n",
        "# you can specify the axis to squeeze\n",
        "print(x.squeeze(1).shape)\n",
        "\n",
        "# trying to squeeze a axis of size > 1 will do nothing\n",
        "print(x.squeeze(0).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9sUBYaF7hfN"
      },
      "source": [
        "### Getting the values of tensor cells"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clJzuzI93U7k",
        "outputId": "9456bd39-3f70-454a-eb91-5a1b4dc55db6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.9118,  1.9291,  0.6433],\n",
            "        [-0.8046, -0.2035, -0.7048]])\n",
            "tensor(-0.8046)\n",
            "torch.Size([])\n",
            "-0.8045608401298523\n"
          ]
        }
      ],
      "source": [
        "#@@ getting the plain value in a tensor's cell\n",
        "x = torch.randn(2,3)\n",
        "print(x)\n",
        "print(x[1,0])\n",
        "print(x[1,0].size())\n",
        "print(x[1,0].item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRbkdZcArlk7"
      },
      "source": [
        "### 1.9 Converting to and from NumPy\n",
        "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
        "\n",
        "The Torch Tensor and NumPy array will **share their underlying memory locations** (if the Torch Tensor is on CPU), and **changing one will change the other**.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlLtucZM3g-N",
        "outputId": "c342a12f-2c50-4032-beb3-c85e4afbb185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original a: tensor([1., 1., 1., 1., 1.])\n",
            "Original b: [1. 1. 1. 1. 1.]\n",
            "New a: tensor([2., 2., 2., 2., 2.])\n",
            "New b: [2. 2. 2. 2. 2.]\n"
          ]
        }
      ],
      "source": [
        "a = torch.ones(5)\n",
        "print(\"Original a:\", a)\n",
        "\n",
        "b = a.numpy()\n",
        "print(\"Original b:\", b)\n",
        "\n",
        "a.add_(1)\n",
        "print(\"New a:\", a)\n",
        "print(\"New b:\", b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cij37AWq31XG",
        "outputId": "3e638ba8-11ce-4213-cec6-bd18fbdb1ad2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2. 2. 2. 2. 2.]\n",
            "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "a = np.ones(5)\n",
        "b = torch.from_numpy(a)\n",
        "np.add(a, 1, out=a)\n",
        "print(a)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-T79NfE4Ck2"
      },
      "source": [
        "### 1.10. CUDA Tensors\n",
        "\n",
        "(cf. wiki page of **CUDA** https://en.wikipedia.org/wiki/Compute_Unified_Device_Architecture :\n",
        "\"CUDA (Compute Unified Device Architecture) is a GPGPU technology (General-Purpose Computing on Graphics Processing Units), namely a technology using a graphical processor (GPU) to execute computations, instead of the central processing unit (CPU).\"\n",
        "\n",
        "Tensors can be moved onto any device using the `.to` method.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbUIutU44psf"
      },
      "source": [
        "### Enable GPU on your Colab notebook\n",
        "\n",
        "Runtime > Change runtime type > Hardware accelerator => select \"T4 GPU\", which is enough\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWaJxd1-4M2w",
        "outputId": "893ebc9f-ad3e-4f5d-f138-48eb39011801"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available? False\n"
          ]
        }
      ],
      "source": [
        "# Try to run this cell with both GPU support and without\n",
        "import torch\n",
        "print(\"CUDA available?\", torch.cuda.is_available())\n",
        "\n",
        "# We will use ``torch.device`` objects to move tensors in and out of GPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")          # a CUDA device object\n",
        "    x = torch.Tensor([1.0, 2.0, 3.0])\n",
        "    y = torch.ones_like(x, device=device)  # directly create a tensor on GPU\n",
        "    x = x.to(device)                       # or just use strings ``.to(\"cuda\")``\n",
        "    z = x + y\n",
        "    print(z)\n",
        "    print(z.to(\"cpu\", torch.double))       # ``.to`` can also change dtype together!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqClHzpw6Lg3"
      },
      "source": [
        "## 2 OPTIONAL for now: Autograd: Automatic Differentiation\n",
        "\n",
        "(\"Differentiation\" = computation of partial derivatives)\n",
        "\n",
        "This part is optional, and meant to understand how pytorch computes (or rather accumulates) gradients behind the scene.\n",
        "See also this blog : https://community.paperspace.com/t/pytorch-basics-understanding-autograd-and-computation-graphs/741\n",
        "which gives a good tutorial on automatic differentiation in pytorch (despite spelling errors and a few mistakes signalled in the comments).\n",
        "\n",
        "\n",
        "The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that the backpropagation will depend on how your code is run, and that every single iteration can be different.\n",
        "\n",
        "``torch.Tensor`` is the central class of the package. If we have a tensor x\n",
        "and set its attribute ``.requires_grad`` as ``True``, it **starts to track all operations made using it**.\n",
        "If for instance z is computed using x, then calling ``z.backward()`` will **automatically update the gradient of z with respect to x**, and accumulate it into the ``x.grad`` attribute: it will add partial derivatives of z with respect to each $x_i$ to the .grad attribute of x**.\n",
        "\n",
        "\n",
        "To **stop a tensor from tracking history**, you can call ``.detach()`` to detach\n",
        "it from the computation history, and to prevent future computation from being\n",
        "tracked.\n",
        "\n",
        "To **prevent tracking history (and using memory)**, you can also wrap the code block\n",
        "in ``with torch.no_grad():``. This can be particularly helpful when **evaluating** a\n",
        "model because the model may have trainable parameters with `requires_grad=True`,\n",
        "but for which we don't need the gradients."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3JXX8xr8HWJ",
        "outputId": "6bfa2385-3bd4-4f18-a33f-906ed40fbc3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuHGuSWn8Pfm",
        "outputId": "725b401b-925b-4865-fd8b-9e4db362d8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "y = x + 2\n",
        "print(y)\n",
        "print(y.requires_grad)\n",
        "\n",
        "# y was created as a result of an operation, so it has a grad_fn and requires_grad=True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylMfa4AP8ZfW",
        "outputId": "e34808e2-0796-4d1c-b975-e4aa3e9f9440"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n",
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ],
      "source": [
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "print(z)\n",
        "print(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbbCf8kM8-hd"
      },
      "source": [
        "``.requires_grad_( ... )`` changes an existing Tensor's ``requires_grad``\n",
        "flag in-place. The input flag defaults to ``False`` if not given.\n",
        "\n",
        "Tensors built using at least one tensor with requires_grad == True also get requires_grad == True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrCqBdbE9Avl",
        "outputId": "00582295-3307-4e0c-cef3-52b4811062f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "True\n",
            "False\n",
            "<SumBackward0 object at 0x7dd03bcf3a30>\n",
            "True\n"
          ]
        }
      ],
      "source": [
        "a = torch.randn(2, 2)\n",
        "a = ((a * 3) / (a - 1))\n",
        "print(a.requires_grad)\n",
        "a.requires_grad_(True)\n",
        "print(a.requires_grad)\n",
        "\n",
        "b = torch.randn(2,2)\n",
        "print(b.requires_grad)\n",
        "\n",
        "c = (a * b).sum()\n",
        "print(c.grad_fn)\n",
        "print(c.requires_grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gonQpAmB-nLL"
      },
      "source": [
        "Let us consider a complete example now.\n",
        "\n",
        "Let :   \n",
        "$z_i = 3(x_i+2)^2$  \n",
        "$out = \\frac{1}{4}\\sum_i z_i$\n",
        "\n",
        "$\\frac{\\partial out}{\\partial x_i} = \\frac{1}{4}\\frac{\\partial z_i}{\\partial x_i} = \\frac{1}{4}\\times 3 \\times 2(x_i+2) = \\frac{3}{2}(x_i+2)$  \n",
        "\n",
        "\n",
        "**When $x_i=1$**:\n",
        "\n",
        "$z_i\\bigr\\rvert_{x_i=1} = 27$\n",
        "\n",
        "$\\frac{\\partial out}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$.\n",
        "\n",
        "\n",
        "**When $x_i=0$**:\n",
        "\n",
        "$z_i\\bigr\\rvert_{x_i=0} = 12$\n",
        "\n",
        "$\\frac{\\partial out}{\\partial x_i}\\bigr\\rvert_{x_i=0} = \\frac{9}{2} = 3$.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbbdshuP-mRz",
        "outputId": "14804e37-6bfa-4511-964d-693c83936e3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1.],\n",
            "        [1., 1.]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([[0., 1.],\n",
            "        [1., 1.]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([[2., 3.],\n",
            "        [3., 3.]], dtype=torch.float64, grad_fn=<AddBackward0>)\n",
            "tensor([[12., 27.],\n",
            "        [27., 27.]], dtype=torch.float64, grad_fn=<MulBackward0>)\n",
            "tensor(23.2500, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "x gradient:\n",
            "tensor([[3.0000, 4.5000],\n",
            "        [4.5000, 4.5000]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "x = torch.tensor( [[0,1],[1,1]], dtype=float, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "out.backward()\n",
        "print(x)\n",
        "print(y)\n",
        "print(z)\n",
        "print(out)\n",
        "print(\"x gradient:\")\n",
        "print(x.grad)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8xobSAS7hfb",
        "outputId": "2ddec8d8-af0d-4d08-8150-ca60a939b5c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0., 1.],\n",
            "        [1., 1.]], dtype=torch.float64, requires_grad=True)\n",
            "tensor([[3.0000, 4.5000],\n",
            "        [4.5000, 4.5000]], dtype=torch.float64)\n",
            "tensor([[6., 9.],\n",
            "        [9., 9.]], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "x = torch.tensor( [[0,1],[1,1]], dtype=float, requires_grad=True)\n",
        "print(x)\n",
        "y = x + 2\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "out.backward()\n",
        "print(x.grad)\n",
        "\n",
        "# again\n",
        "y = x + 2\n",
        "z = y * y * 3\n",
        "out = z.mean()\n",
        "\n",
        "out.backward()\n",
        "print(x.grad)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5716VvqZjfV"
      },
      "source": [
        "We see that every time a variable is back propogated through, the gradient will be **accumulated instead of being replaced**.\n",
        "\n",
        "After parameter updates, one needs to reset gradients to zero\n",
        "(see the `nn.Module.zero_grad()` call in the M1_ML2_TD7.3 notebook)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMBccY8k7hfd"
      },
      "source": [
        "You can stop autograd from tracking history and accumulating gradients by wrapping code with `torch.no_grad()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PveU64No7hfd",
        "outputId": "a822606b-7be3-4da9-fa5a-d876ed97eb25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    t = (10 * x + 3).mean()\n",
        "    # although x has requires_grad == True\n",
        "    print(x.requires_grad)\n",
        "    # this new tensor has requires_grad == False\n",
        "    print(t.requires_grad)\n",
        "\n",
        "# => to be used when testing on validation or test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvVKKkOHaAu0"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}